{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all packages needed\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt #Visualisierungs Package (Vorlesung 5)\n",
    "#Magic command, damit die Diagramme im Notebook angezeigt werden\n",
    "%matplotlib inline \n",
    "import json  #Package um mit json files arbeiten zu können\n",
    "import seaborn as sns #Visualisierungs Package (Vorlesung 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe\n",
    "\n",
    "Quelle: *Diese Übung ist ein Teil aus einem Cornerstone Projekt aus dem Data Analyst Nanodegree von Udacity. Für diese Übung wurden einige Vereinfachungen vorgenommen.*\n",
    "\n",
    "**Beschreibung**:\n",
    "\n",
    "Habt Ihr jemals von dem Twitter-Account WeRateDogs gehört? Die Leute im Internet sind verrückt nach diesem Twitter-Account. Ich möchte Euch heute zeigen, warum. \n",
    "\n",
    "Heute hat WeRateDogs über 8,8 Millionen Follower. Das Schlüsselkonzept besteht darin, ein hübsches Bild der Doggos, Floofer, Pupper oder Puppos (so definieren sie das Entwicklungsstadium der Hunde) mit einer coolen Bildunterschrift und einer Bewertung mit einem Nenner von 10, aber einem Zähler, der alles sein kann, zu haben. In den meisten Fällen geht der Zähler deutlich über 10.\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"src/Picture 1.jpg\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "**Inputdaten:**\n",
    "\n",
    "Ingesamt haben wir 3 verschiedene Dateien, in denen sich aber leider verschiedene Fehler in den Daten befinden\n",
    "- Das Twitter Archive der Tweets\n",
    "- Eine Datei, in der die Rasse des Hundes vorausgesagt wurde\n",
    "- Eine Datei, in der die Anzahl der Likes, Retweets etc pro Tweet steht\n",
    "\n",
    "\n",
    "**Ziel**: \n",
    "\n",
    "Die Dateien wie unten vorgeschrieben zu bereinigen und zu einem Dataframe zusammenzufassen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dokumentation der einzelnen Spalten der verschiedenen Quellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Dokumentation Spalten ***Twitter_archive Dataframe***\n",
    "\n",
    "Dieses Dataframe zeigt die Meta Daten jedes einzelnen Tweets für den betrachteten Zeitraum an.\n",
    "\n",
    "- ***tweet_id*** ist die eineindeutige Twitter Post ID\n",
    "- ***in_reply_to_status_id*** nicht relevant für uns\n",
    "- ***in_reply_to_user_id*** nicht relevant für uns\n",
    "- ***timestamp*** Zeitpunkt des posts\n",
    "- ***source*** nicht relevant für uns\n",
    "- ***text*** Tweet text\n",
    "- ***retweeted_status_id*** ID wenn es ein retweet ist\n",
    "- ***retweeted_status_user_id*** User ID wenn es ein retweet ist\n",
    "- ***retweeted_status_user_timestamp*** User ID wenn es ein retweet ist\n",
    "- ***expanded_urls*** URL des Tweets\n",
    "- ***rating_numerator*** Zähler der Bewertung\n",
    "- ***rating_denominator*** Nenner der Bewertung\n",
    "- ***name*** Name des Hundes\n",
    "- ***doggo*** Hundeentwicklungsstatus\n",
    "- ***floofer*** Hundeentwicklungsstatus\n",
    "- ***pupper*** Hundeentwicklungsstatus\n",
    "- ***puppo*** Hundeentwicklungsstatus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dokumentation Spalten ***Image_prediction Dataframe***\n",
    "\n",
    "Dieses DataFrame stammt aus einem Prediction Maschine Learning Algorithmus, welches an Hand der Bilder, versucht vorauszusagen, welche Rasse der Hund ist\n",
    "\n",
    "- ***tweet_id*** ist die eineindeutige Twitter Post ID\n",
    "- ***jpg_url*** URL des Bildes / der Bilder\n",
    "- ***img_num*** Anzahl der Bilder\n",
    "- ***p1/p2/p3*** Predicted Hunderasse\n",
    "- ***p1_conf/p2_conf/p3_conf*** Wert aus der Klassifikation\n",
    "- ***p1_dog/p2_dog/p3_dog*** Boolean ob der vorausgesagte p1/p2/p3 Wert ein Hund ist ja oder nein\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dokumentation Spalten ***Tweet_json Dataframe***\n",
    "\n",
    "Dieses DataFrame zeigt die numerischen Werte der einzelnen Tweets an.\n",
    "\n",
    "- ***tweet_id*** ist die eineindeutige Twitter Post ID\n",
    "- ***favorite_count*** Wie viele Favorites der Tweet bekommen hat\n",
    "- ***retweet_count*** Wie oft der Tweet geretweeted wurde\n",
    "- ***followers_count*** wie viele Follower es damals gab\n",
    "- ***retweeted_status*** Ob der Tweet der Original Tweet war oder ein Retweet\n",
    "- ***url*** URL des Tweets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data\n",
    "\n",
    "Die nachfolgenden Zellen bis zum Start Der Übung dienen lediglich für Informationszwecke und werden vorgegeben, damit ihr euch schneller auf den wichtigten Teil der Übung, das Data Cleaning fokussieren könnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twitter Archive (Dateiformat CSV) in einen DataFrame laden\n",
    "twitter_archive = pd.read_csv(\"src/twitter-archive-enhanced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bild-Vorhersagen (Image-Predictions - TSV file) in einen DataFrame laden\n",
    "image_prediction = pd.read_csv('src/image-predictions.tsv', sep='\\t' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Herauslesen der interessanten Informationen aus JSON-Wörterbüchern in einer Txt-Datei\n",
    "und in einen DataFrame tweets_json einfügen\n",
    "'''\n",
    "\n",
    "my_demo_list = []\n",
    "with open('src/tweet_json.txt', encoding='utf-8') as json_file:  \n",
    "    all_data = json.load(json_file)\n",
    "    for each_dictionary in all_data:\n",
    "        tweet_id = each_dictionary['id']\n",
    "        whole_tweet = each_dictionary['text']\n",
    "        only_url = whole_tweet[whole_tweet.find('https'):]\n",
    "        favorite_count = each_dictionary['favorite_count']\n",
    "        retweet_count = each_dictionary['retweet_count']\n",
    "        followers_count = each_dictionary['user']['followers_count']\n",
    "        retweeted_status = each_dictionary['retweeted_status'] = each_dictionary.get('retweeted_status', 'Original tweet')\n",
    "        if retweeted_status == 'Original tweet':\n",
    "            url = only_url\n",
    "        else:\n",
    "            retweeted_status = 'This is a retweet'\n",
    "            url = 'This is a retweet'\n",
    "            \n",
    "        my_demo_list.append({'tweet_id': str(tweet_id),\n",
    "                             'favorite_count': int(favorite_count),\n",
    "                             'retweet_count': int(retweet_count),\n",
    "                             'followers_count': int(followers_count),\n",
    "                             'retweeted_status': retweeted_status,\n",
    "                            })\n",
    "        tweet_json = pd.DataFrame(my_demo_list, columns = ['tweet_id', 'favorite_count','retweet_count', \n",
    "                                                           'followers_count', 'retweeted_status', 'url'])\n",
    "                             \n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FINDINGS ###\n",
    "# Es gibt sowohl Originalbewertungen und Retweets\n",
    "# Zeitstempel ist in einem nicht korrekten Datenformat (hier Datetime)\n",
    "# Fehlende Daten in den folgenden Spalten: in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp, expanded_urls\n",
    "# Hundeentwicklungsstufen sind in 4 Spalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FINDINGS ###\n",
    "# Hundestufen sind nicht korrekt angegeben\n",
    "# Der Nenner der Bewertung ist zum Teil größer als 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(twitter_archive.name.unique()=='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FINDINGS ###\n",
    "# Manchmal ist der Name des Hundes None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FINDINGS ###\n",
    "# p1, p2, p3 Hunderassen sind manchmal groß, manchmal klein geschrieben\n",
    "# Die Spalten p1, p2 und p3 enthalten ungültige Daten, wie z. B. ein Vogelhaus, einen Dosenöffner oder einen Brustpanzer usw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FINDINGS ###\n",
    "# tweet_id ist ein String und keine Zahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json.retweeted_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FINDINGS ###\n",
    "# Retweets in diesem df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doppelte Bilder in den URLs enthalen?\n",
    "image_prediction.jpg_url.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anzahl doppelter URLS\n",
    "len(image_prediction.jpg_url) - image_prediction.jpg_url.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FINDINGS ###\n",
    "# Es gibt doppelte Werte (an Hand der URL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.rating_numerator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('max_colwidth', 300):\n",
    "    display(twitter_archive[twitter_archive['text'].str.contains(r\"(\\d+\\.\\d*\\/\\d+)\")]\n",
    "            [['tweet_id', 'text', 'rating_numerator', 'rating_denominator']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FINDINGS ###\n",
    "# Wenn der Zähler eine Dezimalzahl ist wie z.B. 13.5 steht in der Spalte rating_numerator nur die \".5\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start der Übung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Zusammenfassung der Beobachtungen aus erster Datenexploration \n",
    "\n",
    "##### **`twitter_archive`** \n",
    " - Es gibt sowohl Originalbewertungen und Retweets\n",
    " - Es müssen Spalten gelöscht werden, die nicht für die Analyse verwendet werden\n",
    " - Hundestufen sind nicht korrekt angegeben\n",
    " - Zeitstempel ist in einem nicht korrekten Datenformat (hier Datetime)\n",
    " - Fehlende Daten in den folgenden Spalten: in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp, expanded_urls\n",
    " - Der Nenner der Bewertung wird größer als 10\n",
    " - Wenn der Zähler eine Dezimalzahl ist wie z.B. 13.5 steht in der Spalte rating_numerator nur die \".5\" \n",
    " - Manchmal ist der Name des Hundes None\n",
    " - Hundeentwicklungsstufen sind in 4 Spalten\n",
    " - Alle drei Quellen sollen zum Schluss in einem DataFrame sein\n",
    " \n",
    "  \n",
    " ##### **`tweet_json`**\n",
    " - tweet_id ist ein String und keine Zahl\n",
    " - fehlende Daten für die tweet_ids\n",
    " - Retweets in diesem df\n",
    " - Alle drei Quellen sollen zum Schluss in einem DataFrame sein\n",
    " \n",
    " \n",
    " ##### **`image_prediction`** \n",
    " - p1, p2, p3 Hunderassen sind manchmal groß, manchmal klein geschrieben\n",
    " - Die Spalten p1, p2 und p3 enthalten ungültige Daten, wie z. B. ein Vogelhaus, einen Dosenöffner oder einen Brustpanzer usw.\n",
    " - Doppelte Zeilen\n",
    " - Alle drei Quellen sollen zum Schluss in einem DataFrame sein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Aufgaben für euer Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**`twitter_archive`**</br>\n",
    "1. Lösche alle Retweets und behalte die Originalbewertungen in `twitter_archive`\n",
    "2. Lösche folgende Spalten in `twitter_archive`: 'source','in_reply_to_status_id', 'in_reply_to_user_id', 'retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp', 'expanded_urls'\n",
    "3. Konvertiere den Zeitstempel in `twitter_archive` als Datumsformat\n",
    "4. Korrigiere den Zähler in `twitter_archive`. Wandle es erst als `float` um, und korrigiere die 6 falschen Werte manuell\n",
    "5. Entferne alle Zeilen in `twitter_archive`, deren Nenner nicht 10 ist\n",
    "6. Kombinieren alle Spalten der Dog Stages in eine gemeinsame Spalte in `twitter_archive`\n",
    "\n",
    "\n",
    "**`tweet_json`**</br>\n",
    "7. Wandle die tweet_id in ein `int` Format in `tweet_json`</br>\n",
    "8. Lösche alle Retweets und behalte die Originalbewertungen in `tweet_json`\n",
    "</br></br>\n",
    "**`image_predictions`**</br>\n",
    "9. Überabeite die Spalten der Hunderassen in `image_predictions` so, dass nur Kleinbuchstaben enthalten sind</br>\n",
    "10. Lösche alle duplizierten Zeilen (ca. 66) mit Bild in `image_predictions`\n",
    "</br></br>\n",
    "**Übergreifend**</br>\n",
    "11. Erstelle einen DataFrame aus den drei bereinigten DataFrames mit Namen `df`</br>\n",
    "12. Nenne die Spalte text in tweet_text um im Dataframe `df` </br>\n",
    "13. Outlier Rating_numerator erkennen und droppen, mit Hilfe der IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Wir erstellen im ersten Schritt immer eine \"Hartcopy\", \n",
    "auf deren Basis wir dann das Data Cleaning machen damit wir später immer Vergleichen können,\n",
    "ob die Transformationen wirklich funktioniert haben\n",
    "'''\n",
    "twitter_archive_clean = twitter_archive.copy()\n",
    "image_prediction_clean = image_prediction.copy()\n",
    "tweet_json_clean = tweet_json.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Lösche alle Retweets und behalte die Originalbewertungen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Lösche folgende Spalten in `twitter_archive`: 'source','in_reply_to_status_id', 'in_reply_to_user_id', 'retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp', 'expanded_urls'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Konvertiere den Zeitstempel in `twitter_archive` als Datumsformat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Korrigiere den Zähler in `twitter_archive`. Wandle es erst als `float` um, und korrigiere die 6 falschen Werte manuell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE\n",
    "\n",
    "\n",
    "#Manuelles Updaten der Nenner (numerators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "with pd.option_context('max_colwidth', 300):\n",
    "    display(twitter_archive_clean[twitter_archive_clean['text'].str.contains(r\"(\\d+\\.\\d*\\/\\d+)\")]\n",
    "            [['tweet_id', 'text', 'rating_numerator', 'rating_denominator']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Entferne alle Zeilen in `tweet_archive`, deren Nenner nicht 10 ist**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(twitter_archive_clean[twitter_archive_clean[\"rating_denominator\"] != 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Kombinieren alle Spalten der Dog Stages in eine gemeinsame Spalte in `twitter_archive`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE Melt the doggo, floofer, pupper and puppo columns to dogs and dogs_stage column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE drop dogs\n",
    "\n",
    "#CODE Sort by dogs_stage then drop duplicated based on tweet_id except the last occurrence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Wandle die tweet_id in ein `int` Format in `tweet_json`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Lösche alle Retweets und behalte die Originalbewertungen in `tweet_json`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE\n",
    "tweet_json_clean = tweet_json_clean[tweet_json_clean[\"retweeted_status\"]==\"Original tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "tweet_json_clean.retweeted_status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Überarbeite die Spalten der Hunderassen in `image_predictions` so, dass nur Kleinbuchstaben enthalten sind**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Lösche alle duplizierten Zeilen (ca. 66) mit Bild in `image_predictions`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. Erstelle einen DataFrame aus den drei bereinigten DataFrames mit Namen `df`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE Erstellen eines neuen Dataframes df, welches twitter_archive_clean und image_prediction_clean merged\n",
    "\n",
    "#keep rows that have picture (jpg_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE Erstellen eines neuen Dataframes df, welches df_twitter und tweet_json_clean merged\n",
    "\n",
    "\n",
    "#TEST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12. Nenne die Spalte text in tweet_text um im Dataframe `df`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13. Outlier Rating_numerator erkennen und droppen, mit Hilfe der IQR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE - Detect Outlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE - Delete Outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FRAGE: Hat es Sinn gemacht, hier die vermeintlichen Outlier rauszuschmeißen?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ÜBUNG ENDE\n",
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speichern, Analysieren und Visualisieren der Daten\n",
    "\n",
    "Ein kleiner Ausblick in die Übung 5, bei der es dann um die Visualisierung von Daten geht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Speichern der twitter_dogs df in eine CSV Datei\n",
    "df.to_csv('twitter_archive_master.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_stages = df.groupby(\"dogs_stage\")\n",
    "dog_stages.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "g = sns.boxplot(x='dogs_stage',y='retweet_count',data= df,palette='rainbow')\n",
    "g.axes.set_title('Boxplot dog stages and retweet', fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doggo stages has huge outliers, there needs to be more investigation to see why this happens at the doggo stages, besides that puppos have on average the most retweets followed by doggo and floofer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(y='retweet_count', x='rating_numerator', kind='scatter')\n",
    "plt.xlabel('Ratings')\n",
    "plt.ylabel('Retweet Counts')\n",
    "plt.title('Retweet Counts by Ratings Scatter Plot')\n",
    "\n",
    "fig = plt.gcf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen here, the better the rating the more retweets happened the most retweets happend between 12-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dog_type = df.groupby('p1').filter(lambda x: len(x) >= 25)\n",
    "\n",
    "df_dog_type['p1'].value_counts().plot(kind = 'barh')\n",
    "plt.title('Histogram of the Most Rated Dog Type')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Type of dog')\n",
    "\n",
    "fig = plt.gcf() \n",
    "fig.savefig('output.png',bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_types_count = df_dog_type.p1.value_counts()\n",
    "dog_types_avg_rating = df_dog_type.groupby('p1').rating_numerator.mean()\n",
    "\n",
    "df_dog_type.p1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "plt.plot(df.timestamp,df.favorite_count, marker = 'o', linestyle = '', ms = 2)\n",
    "plt.title('Favorite tweet over year')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Fovorite Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "plt.plot(df.timestamp,df.retweet_count, marker = 'o', linestyle = '', ms = 2)\n",
    "plt.title('Retweets over year')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Retweets Count')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
